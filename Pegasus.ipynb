{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "963a9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Script for fine-tuning Pegasus\n",
    "Example usage:\n",
    "  # use XSum dataset as example, with first 1000 docs as training data\n",
    "  from datasets import load_dataset\n",
    "  dataset = load_dataset(\"xsum\")\n",
    "  train_texts, train_labels = dataset['train']['document'][:1000], dataset['train']['summary'][:1000]\n",
    "  \n",
    "  # use Pegasus Large model as base for fine-tuning\n",
    "  model_name = 'google/pegasus-large'\n",
    "  train_dataset, _, _, tokenizer = prepare_data(model_name, train_texts, train_labels)\n",
    "  trainer = prepare_fine_tuning(model_name, tokenizer, train_dataset)\n",
    "  trainer.train()\n",
    " \n",
    "Reference:\n",
    "  https://huggingface.co/transformers/master/custom_datasets.html\n",
    "\"\"\"\n",
    "\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizerFast, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "\n",
    "class PegasusDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels['input_ids'])  # len(self.labels)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f057fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(model_name, \n",
    "                 train_texts, train_labels, \n",
    "                 val_texts=None, val_labels=None, \n",
    "                 test_texts=None, test_labels=None):\n",
    "    \"\"\"\n",
    "    Prepare input data for model fine-tuning\n",
    "    \"\"\"\n",
    "    tokenizer = PegasusTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    prepare_val = False if val_texts is None or val_labels is None else True\n",
    "    prepare_test = False if test_texts is None or test_labels is None else True\n",
    "\n",
    "    def tokenize_data(texts, labels):\n",
    "        encodings = tokenizer(texts, truncation=True, padding=True)\n",
    "        decodings = tokenizer(labels, truncation=True, padding=True)\n",
    "        dataset_tokenized = PegasusDataset(encodings, decodings)\n",
    "        return dataset_tokenized\n",
    "\n",
    "    train_dataset = tokenize_data(train_texts, train_labels)\n",
    "    val_dataset = tokenize_data(val_texts, val_labels) if prepare_val else None\n",
    "    test_dataset = tokenize_data(test_texts, test_labels) if prepare_test else None\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c018f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_fine_tuning(model_name, tokenizer, train_dataset, val_dataset=None, freeze_encoder=False, output_dir='./results'):\n",
    "    \"\"\"\n",
    "    Prepare configurations and base model for fine-tuning\n",
    "    \"\"\"\n",
    "    torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "    if freeze_encoder:\n",
    "        for param in model.model.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    if val_dataset is not None:\n",
    "        training_args = TrainingArguments(\n",
    "          output_dir=output_dir,           # output directory\n",
    "          num_train_epochs=2000,           # total number of training epochs\n",
    "          per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n",
    "          per_device_eval_batch_size=1,    # batch size for evaluation, can increase if memory allows\n",
    "          save_steps=500,                  # number of updates steps before checkpoint saves\n",
    "          save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n",
    "          evaluation_strategy='steps',     # evaluation strategy to adopt during training\n",
    "          eval_steps=100,                  # number of update steps before evaluation\n",
    "          warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "          weight_decay=0.01,               # strength of weight decay\n",
    "          logging_dir='./logs',            # directory for storing logs\n",
    "          logging_steps=10,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "          model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "          args=training_args,                  # training arguments, defined above\n",
    "          train_dataset=train_dataset,         # training dataset\n",
    "          eval_dataset=val_dataset,            # evaluation dataset\n",
    "          tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        training_args = TrainingArguments(\n",
    "          output_dir=output_dir,           # output directory\n",
    "          num_train_epochs=3, #2000      # total number of training epochs\n",
    "          per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n",
    "          save_steps=500,                  # number of updates steps before checkpoint saves\n",
    "          save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n",
    "          warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "          weight_decay=0.01,               # strength of weight decay\n",
    "          logging_dir='./logs',            # directory for storing logs\n",
    "          logging_steps=10,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "          model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "          args=training_args,                  # training arguments, defined above\n",
    "          train_dataset=train_dataset,         # training dataset\n",
    "          tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e49ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install datasets\n",
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset(\"xsum\")\n",
    "# train_texts, train_labels = dataset['train']['document'][:1000], dataset['train']['summary'][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0aad6755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('train_dataset.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    input_texts, input_labels, flows_extracted, models_skipped = data['document'], data['summary'], data['flows_extracted'], data['models_skipped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "853d078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2132\n",
      "2132\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(train_texts))\n",
    "print(len(train_labels))\n",
    "print(len(models_skipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac67fabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640\n",
      "1640\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique_train_labels, label_ind = np.unique(input_labels, return_index=True)\n",
    "train_labels = [input_labels[x] for x in sorted(label_ind)]\n",
    "train_texts = [t for i, t in enumerate(input_texts) if i in label_ind]\n",
    "print(len(unique_train_labels))\n",
    "print(len(train_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ebb4d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<mask_1>, Login, Redirected to homepage, Click \"Create Event\", Enter information about event, Save',\n",
       " 'Validate and process resource request, <mask_1>, Task or Subprocess, Advertise job, Assess applications & shortlist',\n",
       " 'Claim Received, <mask_1>, Request more Information, <mask_1>, <mask_1>, Send Payment to Customer, Reject Claim, <mask_1>, Send Payment to Customer, Reject Claim',\n",
       " '<mask_1>, Iterview, Define process models and related metrics, Publsih models to PCE, Provide comments & feedback, Provide comments & feedback, Collect and review feedback',\n",
       " '<mask_1>, create meeting folder, upload, -1 week, reminder, attend, prepare minutes']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[50:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e25fab8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call www.keskispass.ch',\n",
       " 'Consider candidates at cross-site resource meeting',\n",
       " 'Review Claim, Review Claim, Review Claim, Review Claim',\n",
       " 'Collect process list and scope',\n",
       " 'meeting due']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[50:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e6fd9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1048832532'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flows_extracted[53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c61dd474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 157, 379, 385, 1142, 1380, 1535, 1641]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i, t in enumerate(train_labels) if t == 'RFQ Recieved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c7901cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000982613\n",
      "1138902023\n",
      "1321534353\n",
      "1330479125\n",
      "2019585323\n",
      "282222542\n",
      "450107762\n",
      "558814631\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 157, 379, 385, 1142, 1380, 1535, 1641]:\n",
    "    print(flows_extracted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcd5dc3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1758\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5274\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='5274' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  29/5274 19:36 < 63:29:06, 0.02 it/s, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>12.334800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>12.573100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/63/091b10rd0xl530l7__v0q6jh0000gp/T/ipykernel_44974/4251212532.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_fine_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/monitoring_env/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m                 if (\n",
      "\u001b[0;32m~/Desktop/monitoring_env/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/monitoring_env/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/monitoring_env/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use Pegasus Large model as base for fine-tuning\n",
    "model_name = 'google/pegasus-large'\n",
    "train_dataset, _, _, tokenizer = prepare_data(model_name, train_texts, train_labels)\n",
    "trainer = prepare_fine_tuning(model_name, tokenizer, train_dataset)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3b9ca80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1430644864'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flows_extracted[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e55af6d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Error no file named ['pytorch_model.bin', 'tf_model.h5', 'model.ckpt.index', 'flax_model.msgpack'] found in directory result-1000ds/checkpoint-6000 or `from_tf` and `from_flax` set to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/63/091b10rd0xl530l7__v0q6jh0000gp/T/ipykernel_63697/1038860099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPegasusTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPegasusForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/monitoring_env/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1264\u001b[0m                     \u001b[0marchive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m                     raise EnvironmentError(\n\u001b[0m\u001b[1;32m   1267\u001b[0m                         \u001b[0;34mf\"Error no file named {[WEIGHTS_NAME, TF2_WEIGHTS_NAME, TF_WEIGHTS_NAME + '.index', FLAX_WEIGHTS_NAME]} found in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                         \u001b[0;34mf\"directory {pretrained_model_name_or_path} or `from_tf` and `from_flax` set to False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Error no file named ['pytorch_model.bin', 'tf_model.h5', 'model.ckpt.index', 'flax_model.msgpack'] found in directory result-1000ds/checkpoint-6000 or `from_tf` and `from_flax` set to False."
     ]
    }
   ],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = 'result-1000ds/checkpoint-6000'\n",
    "\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8c3f554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Check results\n",
    "# src_text = input_texts[500]\n",
    "# batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(torch_device)\n",
    "# translated = model.generate(**batch)\n",
    "# tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "# print(tgt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81d7117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies for transformers\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2797e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')\n",
    "# load model\n",
    "model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf658d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01770e2e79694656a1775d45966621cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d23081910c41b2a9b45659e58ff80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39428f15d3ce4cda9f0d4d7a12d99a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65df48f76758486caf9bed5d2c16d2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4658603cc176463bb9e881cc6dcefec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load tokenizer\n",
    "tokenizer_a = PegasusTokenizer.from_pretrained('google/pegasus-aeslc')\n",
    "# load model\n",
    "model_a = PegasusForConditionalGeneration.from_pretrained('google/pegasus-aeslc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d5796768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vacancy, Creat staff requisition, send for approval , <mask_1>, Advertise through Agencies, Advertise through Internal NGA.net, Advertise through External NGA.net, Received applications, 14 days since advertisment , Close Advertisement , Send applications to the Recruitment Manager , Received Nominated applications for Interview , Create short list, <mask_1>, psychometric test, <mask_1>, second interview, Select the Candidate, Determine terms and conditions, Complete Appointment Approval , Offer Appointment, Close Off the Recruitment and Selection Process'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ae9b9a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Approval received , face to face Interview , Conduct two reference check'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_labels[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "af3e463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Vacancy, Creat staff requisition, send for approval , Approval received , Advertise through Agencies, Advertise through Internal NGA.net, Advertise through External NGA.net, Received applications, 14 days since advertisment , Close Advertisement , Send applications to the Recruitment Manager , Received Nominated applications for Interview , Create short list, face to face Interview , psychometric test, Conduct two reference check, second interview, Select the Candidate, Determine terms and conditions, Complete Appointment Approval , Offer Appointment, Close Off the Recruitment and Selection Process'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c7b953c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'URGENT REQUIRES IMMEDIATE ACTION, URGENT'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer_a(text, truncation=True, padding='longest', return_tensors='pt')\n",
    "summary = model_a.generate(**tokens)\n",
    "tokenizer.decode(summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0469ef44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47, 61, 83, 96, 125]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i, t in enumerate(input_labels) if t == 'Daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2f2a785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312704923\n",
      "1421639530\n",
      "1568206019\n",
      "1671787493\n",
      "2065109784\n"
     ]
    }
   ],
   "source": [
    "for i in [47, 61, 83, 96, 125]:\n",
    "    print(flows_extracted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "035f7986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('train_masked_optimized.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    input_texts, input_labels, flows_extracted, models_skipped = data['document'], data['summary'], data['flows_extracted'], data['models_skipped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c225a03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1901\n",
      "1901\n",
      "1901\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(input_texts))\n",
    "print(len(input_labels))\n",
    "print(len(flows_extracted))\n",
    "print(len(models_skipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37162a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1451\n",
      "1451\n",
      "1451\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique_train_labels, label_ind = np.unique(input_labels, return_index=True)\n",
    "train_labels = [input_labels[x] for x in sorted(label_ind)]\n",
    "train_texts = [t for i, t in enumerate(input_texts) if i in label_ind]\n",
    "train_process_models = [t for i, t in enumerate(flows_extracted) if i in label_ind]\n",
    "print(len(train_labels))\n",
    "print(len(train_texts))\n",
    "print(len(train_process_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8fd8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results-masked-optimized-step1.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "data['test_process_models'] = train_process_models[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f72a9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test_texts', 'test_labels', 'test_process_models', 'results'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64c1660a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['test_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1d43fe94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Invoices with errors',\n",
       " \"Sort invoice per Vendor, Enter vendor name, client name, date of arrival at SSP on invoice entry form, Enter invoice process date according to client's SLA on invoice entry form, Follow up further error\",\n",
       " 'Generation of ID Code',\n",
       " 'Give Administration/Director payment details',\n",
       " 'Receive details, Transaction Approved',\n",
       " 'Check quote',\n",
       " 'Request for quote received',\n",
       " 'Check process model , Extent process to L 2, 3',\n",
       " 'decide if person can become member',\n",
       " '6.1. Shipment documents verification, 6.7. Verification of prepared invoice and accounted invoice ',\n",
       " 'phone rings, receive letter',\n",
       " 'takes all letters from Charles',\n",
       " 'Check customer data, Check customers liquidity',\n",
       " '1 week before meeting ',\n",
       " 'prepares plan and valuation',\n",
       " 'check available dishes, ask for tiramisu, ask for check',\n",
       " 'Begin Patent Process',\n",
       " 'Pays for application, Receives info, Checks entrance test and exceptions',\n",
       " 'Personal Information',\n",
       " 'Check Customer, Enter Customer Requirements']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5b45839b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<mask_1>, Next business day, Process invoice, Invoice ready for Validation, Vendor master record needed, Vendor Master Record exception, 11am and 3pm, Invoices collected',\n",
       " \"Invoices from Mail Centre Clerk, Sort invoice per Client, <mask_1>, Staple 'Invoice Entry Form' to invoice, <mask_1>, Post invoice back to Client, Look it up in excel file, <mask_1>, Highlight Invoice as 'Urgent', Send invoice back to Client, Send reminder, Follow up by phone, Disregard invoice, Invoices ready and allocated to Data Entry Officers, Send invoice back to Client, Send reminder, Send reminder, <mask_1>, Disregard invoice, Don't follow up, Don't send reminders, Scalate to experienced SSP member, Invoice from Experienced SSP member\",\n",
       " 'Receive a Cash transfer order, Check reachebility of destination & maximum transfer limit, Insert money to bank account, <mask_1>, min. 2 days, Bank Withdrawal, Receive a requirement for withdrawal., Dispensing cash, Cash',\n",
       " 'BIA office hours, Call BIA office, Request for details, Give Administration/Director requested details, Request for payment, <mask_1>, Receive receipt of payment, Receive enrollment confirmation & materials list, Attend course when it commences',\n",
       " 'Receive phone call, Ask for student details, <mask_1>, Input details into database, Request Payment, Receive payment details, Process Payment, <mask_1>, Send receipt of payment, Send enrollment confirmation & Materials list',\n",
       " 'Submit request for quote, Quote received, <mask_1>, Send order, Send notification',\n",
       " '<mask_1>, Prepare quote, Send quote, Order received, Handle order, Notification received',\n",
       " \"Join team, Agree on team's domain, Create one process model, <mask_1>, Assign penalty points, Fix the process until next session, <mask_1>, Analyze the field of study, Assign roles in the team, Check the process\",\n",
       " \"bring stuff to miranda, <mask_1>, stamps 'new member' and date on letter, hand letter to Charles, add new member to register, calculate fee, ask Charles to write down fee, write down fee, prepares invoice @home, write letter why no membership is possible\",\n",
       " 'receiving shipment documents, <mask_1>, 6.2. Documents complement request sending, 6.3. Completed documents reception, 6.5. Invoice preparation, 6.4. Sending the shipment documents to the client, 6.6. Invoice accounting, <mask_1>, 6.8. Correction of invoicing or accounting, 6.9. Sending of electronic version of invoice, payment receiving, 6.10. Payment booking, 6.11. Payment order, end of the settlement of accounts and documentation proces',\n",
       " \"Send letter, <mask_1>, answer phone, answer questions, <mask_1>, reject fee, pay fees per bank transfer, receive membership card, don't answer phone\",\n",
       " 'Wednesday evening, <mask_1>, stamps new member on the letter and writes date on it, hands over the letter to Charles, calculates fees for the member to pay for the rest of the year, rejects the new membership ',\n",
       " 'Order, <mask_1>, take available customer, create a new customer, <mask_1>, Check inventory, produce it, Take out of stock, delivery invoice, delivery product, message to customer that delivery is not possible',\n",
       " '<mask_1>, reading related meeting documents , holding meeting , reporting to support office , producing minutes , sending minutes to c ommittee members , updating internal records , do qa check on minutes ',\n",
       " 'Need assassination, Secretary takes order, Send data, <mask_1>, Task or Subprocess, contacts with the Mastermind , Mastermind help with the preparation, Contact with Customer',\n",
       " 'Arrive at restaurant, ask for menu, <mask_1>, order a glass of red wine, order salad, <mask_1>, skip dessert , order tiramisu, consume your dishes, <mask_1>, waiter was nice, pay bill and tip, waiter was not nice, pay the bill, leave restaurant',\n",
       " '<mask_1>, EPO Priority Application , PCT Application, PCT Regionalization Phase, USA , Other Competitors? (China, India, etc.), Other Markets? (Japan, etc.), European Countries ',\n",
       " 'Sends filled application to University, Receives application, Sends payment request, Receives payment request, <mask_1>, Accepts application, Sends information about entrance exams, <mask_1>, Takes entrance test, <mask_1>, Sends approval letter, Sends denial letter, Sends exception, Rejects application',\n",
       " '<mask_1>, Previous Study, Upload Documents to Cloud, Personal Needs, Application Review, Terms and Conditions, deadline, Personal Information Review, Previous Study Review, Personal Needs Review, Application Review, Decision, Confirmation, Calendar event',\n",
       " 'Receive Call, <mask_1>, Create Customer, <mask_1>, Tell Customer Discount Conditions']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b967f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
