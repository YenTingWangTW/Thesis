{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from processing_functions import load_JSON, sort_process_flows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ade9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_extracted = []\n",
    "models_skipped = []\n",
    "\n",
    "with open('./filtered_labels.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "bpmn20_filtered_id = data.keys()\n",
    "temp_training_data = {}\n",
    "for file_num in bpmn20_filtered_id:\n",
    "    pools_and_lanes = False\n",
    "    file = '../../thesis_data/bpmai/models/' + file_num + '.json'\n",
    "    try:\n",
    "        results = load_JSON(file)\n",
    "        if len(results) == 4:\n",
    "            pools_and_lanes = True\n",
    "            shapes_id = results[0]\n",
    "            directly_follows = results[1]\n",
    "            lanes = results[2]\n",
    "            pools = results[3]\n",
    "        elif len(results) == 3:\n",
    "            shapes_id = results[0]\n",
    "            directly_follows = results[1]\n",
    "            flows = results[2]\n",
    "        else:\n",
    "            \n",
    "\n",
    "        stencils = set()\n",
    "        tasks_subprocesses_id = set()\n",
    "        # pools_lanes_id = set()\n",
    "        start_events_id = set()\n",
    "        end_events_id = set()\n",
    "        int_events_id = set()\n",
    "        gateways_count = {}\n",
    "        closing_gateways_id = set()\n",
    "        shapes_unwanted_id = set()\n",
    "        tasks_subprocesses = ['Task', 'CollapsedSubprocess', 'Subprocess']\n",
    "        gateways = ['Exclusive_Databased_Gateway', 'InclusiveGateway', 'ParallelGateway']\n",
    "        shapes_unwanted = ['DataObject', 'ITSystem', 'TextAnnotation', \n",
    "                        'Association_Undirected', 'Association_Unidirectional', 'MessageFlow']\n",
    "\n",
    "        for s in shapes_id.keys():\n",
    "            stencils.add(shapes_id[s])\n",
    "            if re.match('(Start.)', shapes_id[s]):\n",
    "                start_events_id.add(s)\n",
    "            if re.match('(End.)', shapes_id[s]):\n",
    "                end_events_id.add(s)\n",
    "            if re.match('(Intermediate.)', shapes_id[s]):\n",
    "                int_events_id.add(s)\n",
    "            if shapes_id[s] in gateways:\n",
    "                gateways_count.update({s: len(directly_follows[s])})\n",
    "                if len(directly_follows[s]) == 1:\n",
    "                    closing_gateways_id.add(s)\n",
    "            if shapes_id[s] in tasks_subprocesses:\n",
    "                tasks_subprocesses_id.add(s)\n",
    "            if shapes_id[s] in shapes_unwanted:\n",
    "                shapes_unwanted_id.add(s)\n",
    "\n",
    "        for f in directly_follows.copy():\n",
    "            if f in shapes_unwanted_id:\n",
    "                directly_follows.pop(f)\n",
    "            if f in directly_follows.keys() and directly_follows[f]:\n",
    "                for r in directly_follows[f]:\n",
    "                    if r in shapes_unwanted_id:\n",
    "                        directly_follows[f].remove(r)\n",
    "\n",
    "        closing_gateways_tasks_count = {}\n",
    "        for g in closing_gateways_id:\n",
    "            count = 0\n",
    "            for f in directly_follows.values():\n",
    "                count += sum(1 if re.match(g, x) else 0 for x in f)\n",
    "            closing_gateways_tasks_count[g] = count\n",
    "\n",
    "        for t in tasks_subprocesses_id:\n",
    "            count = 0\n",
    "            for f in directly_follows.values():\n",
    "                count += sum(1 if re.match(t, x) else 0 for x in f)\n",
    "            if count > 1:\n",
    "                closing_gateways_tasks_count[t] = count\n",
    "\n",
    "        for e in end_events_id:\n",
    "            count = 0\n",
    "            for f in directly_follows.values():\n",
    "                count += sum(1 if re.match(e, x) else 0 for x in f)\n",
    "            if count > 1:\n",
    "                closing_gateways_tasks_count[e] = count\n",
    "\n",
    "        shapes_wanted = set.union(tasks_subprocesses_id, start_events_id, end_events_id, int_events_id)\n",
    "        temp_closing_count = closing_gateways_tasks_count.copy()\n",
    "        file_data = []\n",
    "        for s in start_events_id:\n",
    "            data = []\n",
    "            label = []\n",
    "            flow = directly_follows[s]\n",
    "            result = sort_process_flows(flow, directly_follows, shapes_wanted, gateways_count, temp_closing_count)\n",
    "            result.insert(0,s)\n",
    "            result_copy = result.copy()      \n",
    "\n",
    "            if pools_and_lanes:\n",
    "                names = {}\n",
    "                for x in lanes.values():\n",
    "                    names.update(x)\n",
    "            else:\n",
    "                names = flows\n",
    "            \n",
    "            for n, obj in enumerate(result_copy):\n",
    "                if (obj in start_events_id) or (obj in int_events_id) or (obj in end_events_id):\n",
    "                    if obj in names:\n",
    "                        res = re.findall(r'\\(.*?\\)', names[obj])\n",
    "                        if res:\n",
    "                            names[obj] = res[0][1:-1]\n",
    "                        else:\n",
    "                            result.remove(obj)\n",
    "                if obj in gateways_count:\n",
    "                    result.remove(obj)\n",
    "                \n",
    "            for r in result:\n",
    "                if r in names:\n",
    "                    data.append(names[r])\n",
    "            \n",
    "            file_data.append([x.lower() for x in data])\n",
    "\n",
    "        temp_training_data.update({file_num: file_data})\n",
    "    except:\n",
    "        # print('file skipped - error occurred')\n",
    "        print(file_num)\n",
    "        models_skipped.append(file_num)\n",
    "\n",
    "\n",
    "train_dataset = {'document': temp_training_data, 'models_skipped': models_skipped}\n",
    "\n",
    "with open('labeled_dataset.json', 'w') as f:\n",
    "    json.dump(train_dataset, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1be45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1822ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129be0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python397jvsc74a57bd038b189b07233b7979ce6a7b2f19d07eb3f1cf3ce520727c8dd4113cd02bb1c25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
